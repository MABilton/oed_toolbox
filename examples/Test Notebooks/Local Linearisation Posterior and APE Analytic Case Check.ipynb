{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ee0b609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import oed_toolbox\n",
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cdc9f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "K_func = lambda d: jnp.einsum('...i,...j->...ij', -1*(d-1)**2, (d+1)**0.5)  # jnp.atleast_2d(-1*(d-5)**2 + 20)\n",
    "b_func = lambda d: 0.2*d**(1/2) + 2\n",
    "def create_linear_model(K_func, b_func):\n",
    "    def linear_model(theta, d):\n",
    "        theta = jnp.atleast_1d(theta.squeeze())\n",
    "        return jnp.einsum('ij,j->i', K_func(d), theta) + b_func(d)\n",
    "    return linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73c275cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "prior_mean = jnp.array([1.0, -1.2])\n",
    "prior_cov = jnp.identity(2)\n",
    "noise_cov = 0.1*jnp.identity(2)\n",
    "model_func = create_linear_model(K_func, b_func)\n",
    "model_func_dt = jax.jacfwd(model_func, argnums=0)\n",
    "model = oed_toolbox.models.Model.from_jax_function(model_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dfcb9f",
   "metadata": {},
   "source": [
    "# Likelihood check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3927f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_likelihood(y, theta, d):\n",
    "    y_mean = model_func(theta, d)\n",
    "    return jax.scipy.stats.multivariate_normal.logpdf(y, mean=y_mean, cov=noise_cov)\n",
    "\n",
    "true_likelihood_funcs = \\\n",
    "{'logpdf': jax.vmap(true_likelihood, in_axes=(0,0,0)),\n",
    " 'logpdf_dd': jax.vmap(jax.jacfwd(true_likelihood, argnums=2), in_axes=(0,0,0)), \n",
    " 'logpdf_dy': jax.vmap(jax.jacfwd(true_likelihood, argnums=0), in_axes=(0,0,0)),\n",
    " 'logpdf_dt': jax.vmap(jax.jacfwd(true_likelihood, argnums=1), in_axes=(0,0,0)),\n",
    " 'logpdf_dt_dy': jax.vmap(jax.jacfwd(jax.jacfwd(true_likelihood, argnums=1), argnums=0), in_axes=(0,0,0)),\n",
    " 'logpdf_dt_dd': jax.vmap(jax.jacfwd(jax.jacfwd(true_likelihood, argnums=1), argnums=2), in_axes=(0,0,0)),\n",
    " 'logpdf_dt_dt': jax.vmap(jax.jacfwd(jax.jacfwd(true_likelihood, argnums=1), argnums=1), in_axes=(0,0,0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4aa0af56",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = oed_toolbox.distributions.Likelihood.from_model_plus_constant_gaussian_noise(model, noise_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f428bb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference for logpdf: \n",
      " [1.9073486e-06 0.0000000e+00 3.8146973e-06]\n",
      "Difference for logpdf_dd: \n",
      " [[0.0000000e+00 0.0000000e+00]\n",
      " [4.7683716e-07 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]]\n",
      "Difference for logpdf_dy: \n",
      " [[4.7683716e-07 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]]\n",
      "Difference for logpdf_dt: \n",
      " [[0.0000000e+00 2.3841858e-07]\n",
      " [1.9073486e-06 0.0000000e+00]\n",
      " [0.0000000e+00 0.0000000e+00]]\n",
      "Difference for logpdf_dt_dy: \n",
      " [[[ 0.0000000e+00 -0.0000000e+00]\n",
      "  [ 0.0000000e+00 -0.0000000e+00]]\n",
      "\n",
      " [[-4.7683716e-07  0.0000000e+00]\n",
      "  [ 0.0000000e+00  4.7683716e-07]]\n",
      "\n",
      " [[ 0.0000000e+00 -4.7683716e-07]\n",
      "  [-2.9802322e-08 -4.7683716e-07]]]\n",
      "Difference for logpdf_dt_dd: \n",
      " [[[-9.5367432e-07  0.0000000e+00]\n",
      "  [-4.7683716e-07  0.0000000e+00]]\n",
      "\n",
      " [[ 7.1525574e-07 -3.8146973e-06]\n",
      "  [ 0.0000000e+00 -3.8146973e-06]]\n",
      "\n",
      " [[-1.9073486e-06  0.0000000e+00]\n",
      "  [ 0.0000000e+00  2.8610229e-06]]]\n",
      "Difference for logpdf_dt_dt: \n",
      " [[[ 0.0000000e+00  0.0000000e+00]\n",
      "  [ 0.0000000e+00  0.0000000e+00]]\n",
      "\n",
      " [[-9.5367432e-07  0.0000000e+00]\n",
      "  [ 0.0000000e+00  4.7683716e-07]]\n",
      "\n",
      " [[-4.7683716e-07 -2.3841858e-07]\n",
      "  [-2.3841858e-07 -2.3841858e-07]]]\n"
     ]
    }
   ],
   "source": [
    "y = jnp.array([[1., 0.5], [1., -1.], [-1., -0.6]])\n",
    "theta = jnp.array([[1., 0.1], [0.33, 0.2], [1., 2.]])\n",
    "d = jnp.array([[0.5, 1.], [0.33, 0.2],[1.2, 0.33]])\n",
    "like_vals = likelihood.logpdf(y, theta, d, return_dd=True, return_dt=True, return_dy=True, return_dt_dt=True,\n",
    "                             return_dt_dy=True, return_dt_dd=True)\n",
    "for key, func in true_likelihood_funcs.items():\n",
    "    print(f'Difference for {key}: \\n {func(y,theta,d) - like_vals[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec27252",
   "metadata": {},
   "source": [
    "# Posterior check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53d20568",
   "metadata": {},
   "outputs": [],
   "source": [
    "minimizer = oed_toolbox.optim.gradient_descent_for_map()\n",
    "posterior = oed_toolbox.distributions.Posterior.laplace_approximation(model, minimizer, noise_cov, prior_mean, prior_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1f44b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_icov = jnp.linalg.inv(noise_cov)\n",
    "prior_icov = jnp.linalg.inv(prior_cov)\n",
    "def true_posterior(theta, y, d):\n",
    "    K = K_func(d)\n",
    "    b = b_func(d)\n",
    "    icov = K.T @ noise_icov @ K + prior_icov\n",
    "    cov = jnp.linalg.inv(icov)\n",
    "    mean = ((y-b).T @ noise_icov @ K + prior_mean.T @ prior_icov) @ cov\n",
    "    return jax.scipy.stats.multivariate_normal.logpdf(theta, mean=mean, cov=cov)\n",
    "\n",
    "true_posterior_funcs = \\\n",
    "{'logpdf': jax.vmap(true_posterior, in_axes=(0,0,0)),\n",
    " 'logpdf_dd': jax.vmap(jax.jacfwd(true_posterior, argnums=2), in_axes=(0,0,0)), \n",
    " 'logpdf_dy': jax.vmap(jax.jacfwd(true_posterior, argnums=1), in_axes=(0,0,0))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255887f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference for logpdf: \n",
      " [7.2479248e-05 1.9073486e-06 0.0000000e+00]\n",
      "Difference for logpdf_dd: \n",
      " [[-1.5258789e-04 -1.1444092e-03]\n",
      " [-7.6293945e-06  1.1444092e-05]\n",
      " [-3.3378601e-06  0.0000000e+00]]\n",
      "Difference for logpdf_dy: \n",
      " [[-3.0517578e-05 -3.8146973e-05]\n",
      " [-4.7683716e-07 -4.7683716e-06]\n",
      " [-4.7683716e-07  0.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Nb: can get overflow-related errors if y - f(theta, d) is large\n",
    "theta = jnp.array([[-0.33, 0.2], [1., 2.], [1., 0.1]]) \n",
    "y = jnp.array([ [1., -1.], [-1., -0.6], [1., 0.5]]) \n",
    "d = jnp.array([ [0.33, 0.2], [1.2, 0.33], [0.5, 1.]]) \n",
    "post_vals = posterior.logpdf(theta, y, d, return_dd=True, return_dy=True)\n",
    "for key, func in true_posterior_funcs.items():\n",
    "    print(f'Difference for {key}: \\n {func(theta,y,d) - post_vals[key]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5133f363",
   "metadata": {},
   "source": [
    "# Ape check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cbf19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ape = \\\n",
    "oed_toolbox.losses.APE.using_laplace_approximation(model, \\\n",
    "minimizer, prior_mean,prior_cov, noise_cov, apply_control_variates=False, use_reparameterisation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b7944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmap_true_posterior = jax.vmap(true_posterior, in_axes=(0,0,None))\n",
    "vmap_model_func = jax.vmap(model_func, in_axes=(0,None))\n",
    "noise_chol = jnp.linalg.cholesky(noise_cov)\n",
    "\n",
    "def compute_y(d, epsilon_samples, theta_samples):\n",
    "    return vmap_model_func(theta_samples, d) + jnp.einsum('ij,ai->aj', noise_chol, epsilon_samples)\n",
    "\n",
    "def true_ape(d, theta_samples, epsilon_samples):\n",
    "    y = compute_y(d, epsilon_samples, theta_samples)\n",
    "    post_vals = vmap_true_posterior(theta_samples, y, d)\n",
    "    return -1*jnp.mean(post_vals)\n",
    "\n",
    "true_ape_grad = jax.jacfwd(true_ape, argnums=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc53823f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True values: APE_loss = 1.535464882850647, APE_loss_dd = [-0.52723044  2.4393964 ]\n",
      "Computed Values: APE = 1.5354645252227783, APE_dd = [-0.52722938  2.4393665 ]\n",
      "Difference: APE = -3.5762786865234375e-07, APE_loss_dd = [ 1.0728836e-06 -2.9802322e-05]\n"
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(22)\n",
    "d = jnp.array([1.5, 0.2])\n",
    "num_samples = 1000\n",
    "theta_samples = jax.random.multivariate_normal(rng, mean=prior_mean, cov=prior_cov, shape=(num_samples,))\n",
    "epsilon_samples = jax.random.multivariate_normal(rng, mean=jnp.zeros(noise_cov.shape[0]), \\\n",
    "                                                 cov=jnp.identity(noise_cov.shape[0]), shape=(num_samples,))\n",
    "print(f'True values: APE_loss = {true_ape(d, theta_samples, epsilon_samples)}, APE_loss_dd = {true_ape_grad(d, theta_samples, epsilon_samples)}')\n",
    "ape = ape(d, samples={'epsilon': epsilon_samples, 'theta': theta_samples})\n",
    "print(f\"Computed Values: APE = {ape[0]}, APE_dd = {ape[1]}\")\n",
    "print(f'Difference: APE = {ape[0] - true_ape(d, theta_samples, epsilon_samples)}, APE_loss_dd = {ape[1] - true_ape_grad(d, theta_samples, epsilon_samples)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b637ee5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
